{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthisdict = {\\n  0: \"Yes_Drowsy \",\\n  1: \"No_Drowsy \",\\n \\n}\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "#from time import perf_counter \n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "thisdict = {\n",
    "  0: \"Yes_Drowsy \",\n",
    "  1: \"No_Drowsy \",\n",
    " \n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "model.add(Convolution2D(filters=32, \n",
    "                        kernel_size=(3,3), \n",
    "                        activation= 'relu',\n",
    "                   input_shape=(64, 64, 3)\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(filters=32, \n",
    "                        kernel_size=(3,3), \n",
    "                        activation='relu',\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=60, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                7740      \n",
      "=================================================================\n",
      "Total params: 820,828\n",
      "Trainable params: 820,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "#model.add(Dense(8, activation='softmax'))   # Final Layer using Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                7740      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 122       \n",
      "=================================================================\n",
      "Total params: 820,950\n",
      "Trainable params: 820,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3873 images belonging to 2 classes.\n",
      "Found 1175 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'DataSet/TrainingDataset/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'DataSet/TestDataset/',\n",
    "        target_size=(64, 64,),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit(\\n        training_set,\\n        steps_per_epoch=3873,\\n        epochs=4,\\n        validation_data=test_set,\\n        validation_steps=800)\\n       '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=3873,\n",
    "        epochs=4,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=800)\n",
    "       \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('DrowsySafe2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = load_model('DrowsySafe2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of Classes: [0. 1.]\n",
      "yes Drowsy Detected\n",
      "Number of Categories: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x25D5FAF4848>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pyttsx3\n",
    "n = random.randint(1,21)\n",
    "\n",
    "#if n%2==0:\n",
    "test_image = image.load_img(\"DataSet/SinglePrediction/%d.png\" %n , target_size=(64,64))\n",
    "test_image1 = image.img_to_array(test_image)\n",
    "test_image2 = np.expand_dims(test_image1, axis=0)\n",
    "#print(test_image2)\n",
    "\n",
    "p = m.predict(test_image2)\n",
    "num = np.array(p[0]) \n",
    "\n",
    "num1 = np.array(p[0][1]) \n",
    "print(\"Array of Classes:\",num)\n",
    "\n",
    "if num1 == 1.0:\n",
    "    print(\"yes Drowsy Detected\")\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(\"Hey You are sleeping\")\n",
    "    engine.runAndWait()\n",
    "    \n",
    "else:\n",
    "    print(\"No Drowsy Detected\")\n",
    "\n",
    "print(\"Number of Categories:\",len(num))\n",
    "#print(\"Drowsy_Detected\")\n",
    "test_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "else:\n",
    "    test_image = image.load_img(\"DataSet/SinglePrediction/%d.png\" %n , target_size=(64,64))\n",
    "    test_image1 = image.img_to_array(test_image)\n",
    "    test_image2 = np.expand_dims(test_image1, axis=0)\n",
    "    \n",
    "    p = m.predict(test_image2)\n",
    "    num = np.array(p[0])  \n",
    "    print(num)\n",
    "    print(\"Number of Categories:\",len(num))\n",
    "    #print(\"Category Number:\",n)\n",
    "    #print(\"Check_Drowsy:\",thisdict[n])\n",
    "    print(\"No_Drowsy_Detected\")\n",
    "    \n",
    "    print(test_image)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
